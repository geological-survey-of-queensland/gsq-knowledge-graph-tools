{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a801ec98",
   "metadata": {},
   "source": [
    "# CKAN Metadata to Graph JSON Converter\n",
    "\n",
    "This code will convert CKAN metadata into a graph json structure. The output is two files:\n",
    "\n",
    "- `conformed_graph.json`: this file is a raw graph which is generally compatible with LPG viewers (a basic 2D viewer has been set up at the top of the lpg directory for this purpose)\n",
    "- `viz_graph.json`: this file is configured to work with the Graph3d visualizer\n",
    "\n",
    "## There are four main sections to the code:\n",
    "\n",
    "1. **Get the metadata** - uses a CSV file in the project directory called `report_list.csv`, can be generated manually or using CKAN API Request Builder: [GSQ Labs](https://geological-survey-of-queensland.github.io)\n",
    "\n",
    "2. **Convert each metadata into the graph schema**\n",
    "\n",
    "3. **Conform the metadata into one graph object**  \n",
    "   \\> output: `conformed_graph.json`\n",
    "   This can be loaded into the 2D_lpg_viewer at the top of the lpg directory in the [gsq-knowledge-graph-tools]( https://github.com/geological-survey-of-queensland/gsq-knowledge-graph-tools) repo\n",
    "\n",
    "4. **Convert the `conformed_graph.json` into a Graph3d file**  \n",
    "   \\> output: `vis_graph.json`\n",
    "   This can be loaded into the 3D Graph Viewer: [GSQ Labs](https://geological-survey-of-queensland.github.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c894bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: - generate the metadata json combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4e978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Initialize an empty dict for the combined metadata\n",
    "metadata_combined = {}\n",
    "\n",
    "# Path to the csv file\n",
    "csv_file = 'report_list.csv'\n",
    "\n",
    "# Read the csv file using pandas\n",
    "try:\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Counter for successful package retrievals\n",
    "    successful_packages = 0\n",
    "\n",
    "    # Loop through the values in the 'name' column of the dataframe\n",
    "    for name in df['name']:\n",
    "        # Define the API endpoint with the name appended\n",
    "        api_endpoint = f'https://geoscience.data.qld.gov.au/api/3/action/package_show?id={name}'\n",
    "        \n",
    "        # Try to make a GET request to the API endpoint\n",
    "        try:\n",
    "            response = requests.get(api_endpoint)\n",
    "            \n",
    "            # If the response is successful, add the JSON object to the combined metadata\n",
    "            if response.status_code == 200:\n",
    "                package_data = response.json()\n",
    "                metadata_combined[name] = package_data\n",
    "                successful_packages += 1\n",
    "            else:\n",
    "                # Print an error message if the response is unsuccessful\n",
    "                print(f'Error with package {name}: Received status code {response.status_code}')\n",
    "        \n",
    "        except requests.RequestException as e:\n",
    "            # Print an error message if there's a RequestException\n",
    "            print(f'Error with package {name}: {e}')\n",
    "        except json.JSONDecodeError:\n",
    "            # Print an error message if the response is not valid JSON\n",
    "            print(f'Error with package {name}: Invalid JSON response')\n",
    "\n",
    "    # Print the total number of packages added\n",
    "    print(f'A total of {successful_packages} packages have been added to metadata_combined.')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f'The file {csv_file} does not exist.')\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f'The file {csv_file} is empty or does not contain the \\'name\\' column.')\n",
    "except Exception as e:\n",
    "    # General exception handling for debugging purposes\n",
    "    print(f'An unexpected error occurred: {e}')\n",
    "\n",
    "# Debugging print to show the structure of metadata_combined, this can be removed/commented out\n",
    "# print(json.dumps(metadata_combined, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8290b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2:  convert the ckan package objects to graph format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bcb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "# Initialize a variable to hold the graphs\n",
    "metagraph_objects = []\n",
    "successful_objects = 0\n",
    "\n",
    "# Helper function to stringify JSON objects, leave other types as is\n",
    "def stringify_if_needed(value):\n",
    "    return json.dumps(value) if isinstance(value, dict) else value\n",
    "\n",
    "# Function to create a labelled property graph from a metadata object\n",
    "def create_lpg(metadata):\n",
    "    graph = {\n",
    "        'nodes': [],\n",
    "        'edges': []\n",
    "    }\n",
    "    package_node = {'label': 'package', 'properties': {}}\n",
    "    \n",
    "    # Store the package ID once identified\n",
    "    package_id = None\n",
    "\n",
    "    # Process the metadata object\n",
    "    for key, value in metadata.items():\n",
    "        if key == 'id':\n",
    "            package_id = value  # We expect the ID to be a string already\n",
    "            package_node['id'] = package_id\n",
    "        # Assuming 'resources' is part of the top-level keys\n",
    "        elif key == 'resource_authority_permit':\n",
    "            # Create a unique node for resource_authority_permit\n",
    "            resource_authority_permit_id = 'permit ' + value  # Prepending \"permit \" to create a unique ID\n",
    "            rap_node = {'id': resource_authority_permit_id, 'label': 'resource_authority_permit', 'properties': {key: value}}\n",
    "            graph['nodes'].append(rap_node)\n",
    "            # Create an edge from the package to the resource_authority_permit\n",
    "            edge_id = str(uuid.uuid4())\n",
    "            graph['edges'].append({\n",
    "                'id': edge_id,\n",
    "                'source': package_id,\n",
    "                'target': resource_authority_permit_id,\n",
    "                'label': 'has_permit'\n",
    "            })\n",
    "        elif key == 'resources':\n",
    "            for resource in value:\n",
    "                if isinstance(resource, dict) and 'id' in resource:\n",
    "                    resource_node = {'id': resource['id'], 'label': 'resource', 'properties': {}}\n",
    "                    for prop_key, prop_value in resource.items():\n",
    "                        resource_node['properties'][prop_key] = stringify_if_needed(prop_value)\n",
    "                    graph['nodes'].append(resource_node)\n",
    "                    edge_id = str(uuid.uuid4())\n",
    "                    graph['edges'].append({\n",
    "                        'id': edge_id,\n",
    "                        'source': package_id,\n",
    "                        'target': resource_node['id'],\n",
    "                        'label': 'has_resource'\n",
    "                    })\n",
    "        # For other keys that are not special cases\n",
    "        elif isinstance(value, list) and all(isinstance(item, str) for item in value):\n",
    "            # Process list of strings as separate nodes with edges\n",
    "            for item in value:\n",
    "                node_id = item\n",
    "                graph['nodes'].append({'id': node_id, 'label': key, 'properties': {}})\n",
    "                edge_id = str(uuid.uuid4())\n",
    "                graph['edges'].append({\n",
    "                    'id': edge_id,\n",
    "                    'source': metadata[\"id\"],\n",
    "                    'target': node_id,\n",
    "                    'label': f'has_{key}'\n",
    "                })\n",
    "        # For non-array, string/bool properties of the package node\n",
    "        elif isinstance(value, (bool, str)):\n",
    "            package_node['properties'][key] = stringify_if_needed(value)\n",
    "\n",
    "    graph['nodes'].append(package_node)\n",
    "    return graph\n",
    "\n",
    "# Iterate through metadata_combined and apply the above function\n",
    "for package_id, metadata in metadata_combined.items():\n",
    "    try:\n",
    "        # Check if 'result' key exists and process its content\n",
    "        if 'result' in metadata:\n",
    "            graph = create_lpg(metadata['result'])\n",
    "            metagraph_objects.append(graph)\n",
    "            successful_objects += 1\n",
    "        else:\n",
    "            print(f'Error: Package {package_id} does not have a \"result\" key.')\n",
    "    except Exception as e:\n",
    "        print(f'Error processing package {package_id}: {e}')\n",
    "\n",
    "print(f'Number of objects processed successfully: {successful_objects}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: conform all these separate graph objects into one graph object, removing dupes etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d28c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize conformed_graph structure\n",
    "conformed_graph = {\"nodes\": [], \"edges\": []}\n",
    "\n",
    "# Helper function to check if a node with the same ID already exists\n",
    "def node_exists(nodes_list, node_id):\n",
    "    return any(node['id'] == node_id for node in nodes_list)\n",
    "\n",
    "# Create a mapping from node ids to nodes to efficiently check for existing nodes\n",
    "node_id_to_node = {}\n",
    "\n",
    "# Combine nodes from all graphs, checking for duplicates\n",
    "for graph in metagraph_objects:\n",
    "    for node in graph['nodes']:\n",
    "        if node['id'] not in node_id_to_node:\n",
    "            conformed_graph['nodes'].append(node)\n",
    "            node_id_to_node[node['id']] = node\n",
    "\n",
    "# Combine edges from all graphs\n",
    "for graph in metagraph_objects:\n",
    "    for edge in graph['edges']:\n",
    "        # Ensure that both 'source' and 'target' have corresponding nodes\n",
    "        if edge['source'] in node_id_to_node and edge['target'] in node_id_to_node:\n",
    "            conformed_graph['edges'].append(edge)\n",
    "        else:\n",
    "            # Normally, you would log this or handle it in some way\n",
    "            print(f\"Warning: Edge with source {edge['source']} and target {edge['target']} was omitted due to missing node reference.\")\n",
    "\n",
    "# Print the total number of nodes and edges in the conformed_graph object\n",
    "print(f\"Total number of nodes: {len(conformed_graph['nodes'])}\")\n",
    "print(f\"Total number of edges: {len(conformed_graph['edges'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5382b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: convert the graph-3d version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e809fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Default node and edge structures based on the given example\n",
    "default_node_structure = {\n",
    "    \"id\": None,\n",
    "    \"count\": 1,\n",
    "    \"description\": None,\n",
    "    \"properties\": {},\n",
    "    \"size\": 20,\n",
    "    \"group\": None,\n",
    "    \"visible\": True,\n",
    "    \"overrideColor\": False,\n",
    "    \"color\": None,\n",
    "    \"opacity\": 0.5\n",
    "}\n",
    "\n",
    "default_edge_structure = {\n",
    "    \"source\": None,\n",
    "    \"target\": None,\n",
    "    \"description\": None,\n",
    "    \"count\": 1,\n",
    "    \"properties\": {},\n",
    "    \"thickness\": 3,\n",
    "    \"value\": 1,\n",
    "    \"visible\": True,\n",
    "    \"overrideColor\": False,\n",
    "    \"color\": \"#33FFFF\",\n",
    "    \"particleColor\": \"#FFFF33\",\n",
    "    \"linkLabelVisible\": True\n",
    "}\n",
    "\n",
    "# Define a function to get a unique color for each group\n",
    "def assign_color(group):\n",
    "    color_map = {\n",
    "        \"package\": \"#ff00ff\",\n",
    "        \"resource\": \"#0c64e8\",\n",
    "        \"resource_authority_permit\": \"#0000cd\"\n",
    "        # You can add more predefined group colors here\n",
    "    }\n",
    "    return color_map.get(group, \"#d3d3d3\")  # Default color if group not found\n",
    "\n",
    "# Initialize vis_graph with the given structures\n",
    "vis_graph = {\n",
    "    \"nodes\": [],\n",
    "    \"links\": []\n",
    "}\n",
    "\n",
    "# Process the conformed graph into vis_graph format\n",
    "existing_node_ids = set()  # Keep track of existing node IDs to avoid duplicates\n",
    "for node in conformed_graph[\"nodes\"]:\n",
    "    if node[\"id\"] not in existing_node_ids:\n",
    "        vis_node = default_node_structure.copy()\n",
    "        # Use 'title' if it exists, if not 'name', and if neither, fall back to `node['id']`\n",
    "        description = node[\"properties\"].get(\"title\", node[\"properties\"].get(\"name\", node[\"id\"]))\n",
    "        vis_node.update({\n",
    "            \"id\": node[\"id\"],\n",
    "            \"description\": description,\n",
    "            \"group\": node[\"label\"],\n",
    "            \"color\": assign_color(node[\"label\"]),\n",
    "            \"properties\": node[\"properties\"]  # Assuming properties is a dict, converting to a list\n",
    "        })\n",
    "        vis_graph[\"nodes\"].append(vis_node)\n",
    "        existing_node_ids.add(node[\"id\"])\n",
    "\n",
    "for edge in conformed_graph[\"edges\"]:\n",
    "    vis_edge = default_edge_structure.copy()\n",
    "    vis_edge.update({\n",
    "        \"source\": edge[\"source\"],\n",
    "        \"target\": edge[\"target\"],\n",
    "        \"description\": edge[\"label\"]\n",
    "    })\n",
    "    vis_graph[\"links\"].append(vis_edge)\n",
    "\n",
    "# Output directory\n",
    "output_directory = \"output\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Function to save JSON content to file\n",
    "def save_json_content(filename, content):\n",
    "    filepath = os.path.join(output_directory, filename)\n",
    "    with open(filepath, 'w') as file:\n",
    "        json.dump(content, file, indent=4)\n",
    "    return filepath\n",
    "\n",
    "# Save both graphs as JSON files\n",
    "try:\n",
    "    conformed_graph_path = save_json_content(\"conformed_graph.json\", conformed_graph)\n",
    "    print(f\"{conformed_graph_path} has been saved successfully.\")\n",
    "    \n",
    "    vis_graph_path = save_json_content(\"vis_graph.json\", vis_graph)\n",
    "    print(f\"{vis_graph_path} has been saved successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while saving the JSON files:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
